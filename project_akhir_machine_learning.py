# -*- coding: utf-8 -*-
"""Project-Akhir-Machine-Learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19z7K_U_kaoTnp5VPvbwOJjCJZWUUBHXv

# **Problem dan Goals**

Berdasarkan analisis data Global Economy Indicators, berikut insights utama:

Problems:
1. Kesenjangan signifikan antar negara dalam indikator ekonomi
2. Korelasi kuat antara tata kelola (governance) dengan kinerja ekonomi
3. Beberapa negara memiliki skor sangat rendah di keamanan dan kebebasan personal

Goals:
1. Mengelompokkan negara berdasarkan karakteristik ekonomi (menggunakan K-means clustering)
2. Mengidentifikasi faktor-faktor yang paling berpengaruh terhadap skor rata-rata ekonomi
3. Menemukan pola dan hubungan antar indikator untuk pembuatan kebijakan

Dari analisis clustering:
- Optimal cluster = 3 (berdasarkan elbow method dan silhouette score)
- Negara dapat dikelompokkan menjadi: ekonomi maju, berkembang, dan tertinggal

Temuan ini dapat membantu pembuat kebijakan untuk:
- Mengidentifikasi area prioritas perbaikan
- Merancang intervensi berdasarkan karakteristik cluster
- Menetapkan target pembangunan yang realistis

# **Dataset**
Jumlah Baris: 167

Jumlah Kolom: 14

Numerical Features (Fitur Numerik):
* AveragScore,
* SafetySecurity,
* PersonelFreedom,
* Governance, SocialCapital,
* InvestmentEnvironment,
* EnterpriseConditions,
* MarketAccessInfrastructure,
* EconomicQuality,
* LivingConditions,
* Health,
* Education,
* NaturalEnvironment

Categorical Features (Fitur Kategorikal):

*  Country

# **Codingan**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.pipeline import Pipeline
import pickle
import warnings
warnings.filterwarnings('ignore')
import matplotlib.pyplot as plt

data = pd.read_csv('data.csv')
data.head()

features = ['SafetySecurity', 'PersonelFreedom', 'Governance',
           'SocialCapital', 'InvestmentEnvironment', 'EnterpriseConditions',
           'MarketAccessInfrastructure', 'EconomicQuality', 'LivingConditions',
           'Health', 'Education', 'NaturalEnvironment']
df = data[features]
X = df[features]

df.describe()

df.info()

df.isnull().sum()

import seaborn as sns

# Set figure size
plt.figure(figsize=(15, 40))

# Create subplots for each column
for idx, column in enumerate(df.columns[0:], 1): # Skip Country column
   plt.subplot(7, 2, idx)
   sns.histplot(data=df, x=column, bins=30, color='darkblue', alpha=0.7)
   plt.title(f'Distribution of {column}')
   plt.xlabel(column)
   plt.ylabel('Count')
   plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

# Create subplot for all numerical columns
plt.figure(figsize=(15, 40))

# Plot boxplots
for idx, column in enumerate(df.columns[1:], 1): # Skip Country column
   plt.subplot(7, 2, idx)
   sns.boxplot(data=df, y=column, color='darkblue')
   plt.title(f'Distribution of {column}')
   plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

plt.figure(figsize=(15, 40))

# Loop melalui setiap fitur numerik
for idx, column in enumerate(df.columns[1:], 1):  # Lewati kolom 'Country'
    # Buat subplot untuk setiap fitur
    plt.subplot(7, 2, idx)

    # Hitung batas atas dan bawah untuk mendeteksi outlier
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Filter data untuk menghapus outlier
    filtered_data = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]

    # Buat box plot tanpa outlier
    sns.boxplot(data=filtered_data, y=column, color='darkblue', showfliers=False)
    plt.title(f'Distribusi {column} (Tanpa Outlier)')
    plt.xticks(rotation=45)

# Atur layout dan tampilkan plot
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Create correlation matrix
plt.figure(figsize=(15, 10))
sns.heatmap(df.iloc[:, 0:].corr(),
           annot=True,
           cmap='coolwarm',
           fmt='.2f',
           square=True,
           annot_kws={'size': 8})

plt.title('Correlation Heatmap of Global Economy Indicators')
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

from sklearn.metrics.cluster import silhouette_score
sse = {};sil = [];kmax = 10
fig = plt.subplots(nrows = 1, ncols = 2, figsize = (20,5))

# Elbow Method :
plt.subplot(1,2,1)
for k in range(1, 10):
    kmeans = KMeans(n_clusters=k, max_iter=1000).fit(df)
    sse[k] = kmeans.inertia_ # Inertia: Sum of distances of samples to their closest cluster center
sns.lineplot(x = list(sse.keys()), y = list(sse.values()));
plt.title('Elbow Method')
plt.xlabel("k : Number of cluster")
plt.ylabel("Sum of Squared Error")

# Silhouette Score Method
plt.subplot(1,2,2)
for k in range(2, kmax + 1):
    kmeans = KMeans(n_clusters = k).fit(df)
    labels = kmeans.labels_
    sil.append(silhouette_score(df, labels, metric = 'euclidean'))
sns.lineplot(x = range(2,kmax + 1), y = sil);
plt.title('Silhouette Score Method')
plt.xlabel("k : Number of cluster")
plt.ylabel("Silhouette Score")
plt.show()

pca = PCA(n_components=2)
principalComponents = pca.fit_transform(X)

principalDf = pd.DataFrame(data = principalComponents,
                          columns = ['principal component 1', 'principal component 2'])


from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=3, random_state=42)
cluster_labels = kmeans.fit_predict(X)

finalDf = pd.concat([principalDf, pd.Series(cluster_labels, name='Cluster')], axis=1)

fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(1, 1, 1)
ax.set_xlabel('Principal Component 1', fontsize=15)
ax.set_ylabel('Principal Component 2', fontsize=15)
ax.set_title('2 Component PCA with Clusters', fontsize=20)

# Define targets and colors for each cluster
targets = [0, 1, 2]  # Cluster labels
colors = ['r', 'g', 'b']  # Colors for each cluster

for target, color in zip(targets, colors):
    indicesToKeep = finalDf['Cluster'] == target
    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1'],
              finalDf.loc[indicesToKeep, 'principal component 2'],
              c=color,
              s=50,
              label=f'Cluster {target}')

ax.legend()
ax.grid()
explained_var = pca.explained_variance_ratio_
plt.xlabel(f'Principal Component 1 ({explained_var[0]:.2%} explained variance)')
plt.ylabel(f'Principal Component 2 ({explained_var[1]:.2%} explained variance)')

plt.grid(True)
plt.show()

"""PC1 mungkin merepresentasikan "Kekuatan Ekonomi & Infrastruktur" karena memiliki bobot tinggi pada indikator ekonomi

PC2 mungkin merepresentasikan "Kualitas Hidup & Sosial" karena berkaitan dengan kesehatan, pendidikan, dan kebebasan personal

Cluster 0 (Merah): Terletak di tengah grafik, menunjukkan negara-negara dengan karakteristik ekonomi menengah

Cluster 1 (Hijau): Berada di sebelah kiri grafik, kemungkinan merepresentasikan negara-negara dengan tantangan ekonomi yang lebih besar

Cluster 2 (Biru): Terletak di sebelah kanan grafik, mungkin menunjukkan negara-negara dengan ekonomi yang lebih majupengembangan
"""

feature_weights = pd.DataFrame(
    pca.components_.T,
    columns=['PC1', 'PC2'],
    index=features
)
print("\nKontribusi Fitur to principal components:")
print(feature_weights)

# Calculate total explained variance
total_var = sum(explained_var)
print(f"\nTotal explained variance: {total_var:.2%}")

"""Meskipun tampak kontradiktif, negara dengan tantangan ekonomi besar mungkin memiliki skor PC2 yang tinggi karena beberapa faktor, termasuk kombinasi skor pada berbagai fitur, variasi internal cluster, pengaruh scaling, kompleksitas data, dan interpretasi PC2 yang lebih luas. Penting untuk diingat bahwa PCA dan clustering adalah alat penyederhanaan data, dan interpretasi hasil harus dilakukan dengan hati-hati dan mempertimbangkan konteks data yang dianalisis."""

# Dilakukan data drop dan dipilih Feature terbaik berdasarkan PCA (Principal Components Analysis)

# Pemilihan Fitur
important_features = ['SocialCapital', 'Governance', 'EconomicQuality', 'LivingConditions']
dfinal = df[important_features] # Buat DataFrame baru dengan fitur terpilih
XF = dfinal[important_features] # (Baris ini bisa dihapus, karena redundant)

# Standarisasi/Scaling pada data yang telah dipilih fiturnya
X_scaled = StandardScaler().fit_transform(XF) # Scaling pada XF, bukan X lagi
scaler = StandardScaler()
scaler.fit(XF)

optimal_k = 3
kmeans = KMeans(n_clusters=optimal_k, random_state=42)
kmeans.fit(X_scaled)

import numpy as np
from sklearn import datasets
from sklearn.model_selection import KFold
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt
#from mpl_toolkits.mplot3d import Axes3D # Dihapus karena tidak digunakan

# --- Perubahan 1: Pilih fitur yang relevan ---
features = df[['SocialCapital', 'Governance', 'EconomicQuality', 'LivingConditions']]
# Ganti dengan fitur penting yang Anda identifikasi dari PCA

# --- Perubahan 2: Normalisasi data ---
from sklearn.preprocessing import StandardScaler # Pastikan import StandardScaler
scaler = StandardScaler()
features_scaled = scaler.fit_transform(features)

# --- Perubahan 3: Range jumlah cluster ---
cluster_range = range(2, 10)  # Sesuaikan jika perlu

cv_results = {}
elbow_sse = []

print("Processing Clusters...\n")
print("Clusters | SSE               | Mean Silhouette Score")
print("-" * 50)

# --- Perubahan 4: Loop evaluasi cluster ---
for n_clusters in cluster_range:
    cv_silhouette_scores = []
    sse = 0

    for train_index, test_index in KFold(n_splits=5, shuffle=True, random_state=42).split(features_scaled):
        X_train, X_test = features_scaled[train_index], features_scaled[test_index]

        kmeans = KMeans(n_clusters=n_clusters, random_state=42)
        kmeans.fit(X_train)

        test_labels = kmeans.predict(X_test)
        score = silhouette_score(X_test, test_labels)
        cv_silhouette_scores.append(score)

        sse += kmeans.inertia_

    mean_silhouette_score = np.mean(cv_silhouette_scores)
    mean_sse = sse / 5

    cv_results[n_clusters] = mean_silhouette_score
    elbow_sse.append(mean_sse)

    print(f"{n_clusters:^8} | {mean_sse:<16.4f} | {mean_silhouette_score:<.4f}")

# --- Perubahan 5: Jumlah cluster optimal ---
optimal_clusters = 3  # Ganti dengan jumlah cluster optimal Anda

final_kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)
final_labels = final_kmeans.fit_predict(features_scaled)

final_silhouette_score = silhouette_score(features_scaled, final_labels)
print(f"Final Silhouette Score on Test Set: {final_silhouette_score}")

# --- Perubahan 6: Tambahkan label cluster ke DataFrame ---
data['cluster'] = final_labels  # Ganti 'data' dengan nama DataFrame Anda

# --- Perubahan 7: Ringkasan cluster (sesuaikan dengan fitur Anda) ---
cluster_summary = data.groupby('cluster')[['SocialCapital', 'Governance', 'EconomicQuality', 'LivingConditions']].mean()
# Ganti dengan fitur yang ingin Anda analisis
print("\nDataframe dengan cluster:")
print(data) # Ganti 'data' dengan nama DataFrame
print("\nRingkasan cluster:")
print(cluster_summary)

# Plot grafik Elbow Method dan Silhouette Score
plt.figure(figsize=(14, 6))

# Grafik Elbow Method
plt.subplot(1, 2, 1)
plt.plot(cluster_range, elbow_sse, marker='o', label='SSE')
plt.title('Elbow Method (SSE vs. Number of Clusters)')
plt.xlabel('Number of Clusters')
plt.ylabel('Sum of Squared Error (SSE)')
plt.xticks(cluster_range)
plt.grid(True)
plt.legend()

# Grafik Silhouette Score
plt.subplot(1, 2, 2)
plt.plot(cluster_range, [cv_results[k] for k in cluster_range], marker='o', color='orange', label='Silhouette Score')
plt.title('Silhouette Score vs. Number of Clusters')
plt.xlabel('Number of Clusters')
plt.ylabel('Silhouette Score')
plt.xticks(cluster_range)
plt.grid(True)
plt.legend()

plt.tight_layout()
plt.show()

# Contoh visualisasi 2D dengan PCA:
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
principalComponents = pca.fit_transform(features_scaled)

principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])
finalDf = pd.concat([principalDf, data['cluster']], axis = 1)

plt.figure(figsize=(8, 6))
sns.scatterplot(x="principal component 1", y="principal component 2", hue="cluster", data=finalDf, palette="viridis")
plt.title('Visualisasi Cluster')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.show()

# Saat melatih model

# # Simpan scaler ke file
pickle.dump(scaler, open('scaler.pkl', 'wb'))

# Simpan model KMeans
pickle.dump(kmeans, open('kmeans_model.pkl', 'wb'))